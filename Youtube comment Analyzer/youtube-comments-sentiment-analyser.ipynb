{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40f37ab4",
   "metadata": {
    "papermill": {
     "duration": 0.006825,
     "end_time": "2022-09-30T03:58:29.759255",
     "exception": false,
     "start_time": "2022-09-30T03:58:29.752430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataextraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d3839d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:29.774969Z",
     "iopub.status.busy": "2022-09-30T03:58:29.774270Z",
     "iopub.status.idle": "2022-09-30T03:58:29.779218Z",
     "shell.execute_reply": "2022-09-30T03:58:29.778334Z"
    },
    "papermill": {
     "duration": 0.015409,
     "end_time": "2022-09-30T03:58:29.781518",
     "exception": false,
     "start_time": "2022-09-30T03:58:29.766109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r3/xkrh3r1x2ql7n4nzh4vwp9_r0000gn/T/ipykernel_52794/1260921901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Youtube links: https://youtu.be/uYPbbksJxIg \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msaved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output name: Oppenheimer \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0myoutube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#from youtube_comment_scraper_python import *\n",
    "#import pandas as pd\n",
    "\n",
    "#link = input(\"Youtube links: https://youtu.be/uYPbbksJxIg \")\n",
    "#saved = input(\"Output name: Oppenheimer \")\n",
    "#youtube.open(link)\n",
    "\n",
    "#response = youtube.video_comments()\n",
    "#all_data = []\n",
    "#for i in range(0, 20): # It will scroll 10 times\n",
    "#    response = youtube.video_comments()\n",
    "#    data = response['body']\n",
    "#    all_data.extend(data)\n",
    "#df = pd.DataFrame(data)\n",
    "#df.to_csv(saved)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5760afce",
   "metadata": {
    "papermill": {
     "duration": 0.00732,
     "end_time": "2022-09-30T03:58:29.796844",
     "exception": false,
     "start_time": "2022-09-30T03:58:29.789524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Datatransformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab538562",
   "metadata": {
    "papermill": {
     "duration": 0.006856,
     "end_time": "2022-09-30T03:58:29.811210",
     "exception": false,
     "start_time": "2022-09-30T03:58:29.804354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Libraries required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b487549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:29.827839Z",
     "iopub.status.busy": "2022-09-30T03:58:29.827230Z",
     "iopub.status.idle": "2022-09-30T03:58:31.873350Z",
     "shell.execute_reply": "2022-09-30T03:58:31.871942Z"
    },
    "papermill": {
     "duration": 2.057974,
     "end_time": "2022-09-30T03:58:31.876518",
     "exception": false,
     "start_time": "2022-09-30T03:58:29.818544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Libraries \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# Import functions for data preprocessing & data preparation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dd11013",
   "metadata": {
    "papermill": {
     "duration": 0.006969,
     "end_time": "2022-09-30T03:58:31.891089",
     "exception": false,
     "start_time": "2022-09-30T03:58:31.884120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d31585e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:31.910064Z",
     "iopub.status.busy": "2022-09-30T03:58:31.909567Z",
     "iopub.status.idle": "2022-09-30T03:58:31.954451Z",
     "shell.execute_reply": "2022-09-30T03:58:31.952746Z"
    },
    "papermill": {
     "duration": 0.057343,
     "end_time": "2022-09-30T03:58:31.957543",
     "exception": false,
     "start_time": "2022-09-30T03:58:31.900200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love how Dr. Fate's design looks and how cool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can’t get over how good everything looks. Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really hoping that this can save DC's movie un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U cant deny how good this looks.Now if they ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From this trailer, I have a feeling that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>I want to see this. It may be one of his most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>wow thats very amazing. I can't wait to see.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Doctor Fate is why i'm watching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>This looks fire. DC looks like they stepping t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Shazam : \"I don't want fight you Black Adam.\"B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment\n",
       "0    Love how Dr. Fate's design looks and how cool ...\n",
       "1    I can’t get over how good everything looks. Dr...\n",
       "2    Really hoping that this can save DC's movie un...\n",
       "3    U cant deny how good this looks.Now if they ca...\n",
       "4    From this trailer, I have a feeling that this ...\n",
       "..                                                 ...\n",
       "275  I want to see this. It may be one of his most ...\n",
       "276       wow thats very amazing. I can't wait to see.\n",
       "277                    Doctor Fate is why i'm watching\n",
       "278  This looks fire. DC looks like they stepping t...\n",
       "279  Shazam : \"I don't want fight you Black Adam.\"B...\n",
       "\n",
       "[280 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/satyamchoubey/Desktop/comments.csv\")\n",
    "data.columns\n",
    "data1=data.drop(['Unnamed: 0','Likes','Time','user','UserLink'],axis=1)\n",
    "data1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9ae7728",
   "metadata": {
    "papermill": {
     "duration": 0.007332,
     "end_time": "2022-09-30T03:58:31.972749",
     "exception": false,
     "start_time": "2022-09-30T03:58:31.965417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Data labelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771e9208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:31.990695Z",
     "iopub.status.busy": "2022-09-30T03:58:31.990229Z",
     "iopub.status.idle": "2022-09-30T03:58:32.536210Z",
     "shell.execute_reply": "2022-09-30T03:58:32.534890Z"
    },
    "papermill": {
     "duration": 0.558513,
     "end_time": "2022-09-30T03:58:32.539262",
     "exception": false,
     "start_time": "2022-09-30T03:58:31.980749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/satyamchoubey/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love how Dr. Fate's design looks and how cool ...</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can’t get over how good everything looks. Dr...</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really hoping that this can save DC's movie un...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U cant deny how good this looks.Now if they ca...</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From this trailer, I have a feeling that this ...</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Positive  Negative  \\\n",
       "0  Love how Dr. Fate's design looks and how cool ...     0.384     0.000   \n",
       "1  I can’t get over how good everything looks. Dr...     0.153     0.000   \n",
       "2  Really hoping that this can save DC's movie un...     0.375     0.000   \n",
       "3  U cant deny how good this looks.Now if they ca...     0.302     0.049   \n",
       "4  From this trailer, I have a feeling that this ...     0.131     0.000   \n",
       "\n",
       "   Neutral  Compound Sentiment  \n",
       "0    0.616    0.8910  Positive  \n",
       "1    0.847    0.6801  Positive  \n",
       "2    0.625    0.9216  Positive  \n",
       "3    0.649    0.9262  Positive  \n",
       "4    0.869    0.4416  Positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data1[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data1[\"Comment\"]]\n",
    "data1[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data1[\"Comment\"]]\n",
    "data1[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data1[\"Comment\"]]\n",
    "data1['Compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in data1[\"Comment\"]]\n",
    "score = data1[\"Compound\"].values\n",
    "sentiment = []\n",
    "for i in score:\n",
    "    if i >= 0.05 :\n",
    "        sentiment.append('Positive')\n",
    "    elif i <= -0.05 :\n",
    "        sentiment.append('Negative')\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "data1[\"Sentiment\"] = sentiment\n",
    "data1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbf8e44d",
   "metadata": {
    "papermill": {
     "duration": 0.008146,
     "end_time": "2022-09-30T03:58:32.555850",
     "exception": false,
     "start_time": "2022-09-30T03:58:32.547704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Final data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d8b85a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:32.574215Z",
     "iopub.status.busy": "2022-09-30T03:58:32.573700Z",
     "iopub.status.idle": "2022-09-30T03:58:32.590306Z",
     "shell.execute_reply": "2022-09-30T03:58:32.588730Z"
    },
    "papermill": {
     "duration": 0.03055,
     "end_time": "2022-09-30T03:58:32.594690",
     "exception": false,
     "start_time": "2022-09-30T03:58:32.564140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love how Dr. Fate's design looks and how cool ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can’t get over how good everything looks. Dr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really hoping that this can save DC's movie un...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U cant deny how good this looks.Now if they ca...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From this trailer, I have a feeling that this ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  Love how Dr. Fate's design looks and how cool ...  Positive\n",
       "1  I can’t get over how good everything looks. Dr...  Positive\n",
       "2  Really hoping that this can save DC's movie un...  Positive\n",
       "3  U cant deny how good this looks.Now if they ca...  Positive\n",
       "4  From this trailer, I have a feeling that this ...  Positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.drop(['Positive','Negative','Neutral','Compound'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71a3ff7c",
   "metadata": {
    "papermill": {
     "duration": 0.007928,
     "end_time": "2022-09-30T03:58:32.611842",
     "exception": false,
     "start_time": "2022-09-30T03:58:32.603914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Data transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e3eb6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:32.630800Z",
     "iopub.status.busy": "2022-09-30T03:58:32.630195Z",
     "iopub.status.idle": "2022-09-30T03:58:32.642756Z",
     "shell.execute_reply": "2022-09-30T03:58:32.641299Z"
    },
    "papermill": {
     "duration": 0.025568,
     "end_time": "2022-09-30T03:58:32.645712",
     "exception": false,
     "start_time": "2022-09-30T03:58:32.620144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/satyamchoubey/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer() \n",
    "snowball_stemer = SnowballStemmer(language=\"english\")\n",
    "lzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43dc397b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:32.664853Z",
     "iopub.status.busy": "2022-09-30T03:58:32.664120Z",
     "iopub.status.idle": "2022-09-30T03:58:32.671665Z",
     "shell.execute_reply": "2022-09-30T03:58:32.670853Z"
    },
    "papermill": {
     "duration": 0.019897,
     "end_time": "2022-09-30T03:58:32.674206",
     "exception": false,
     "start_time": "2022-09-30T03:58:32.654309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_processing(text):   \n",
    "    # convert text into lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove new line characters in text\n",
    "    text = re.sub(r'\\n',' ', text)\n",
    "    \n",
    "    # remove punctuations from text\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n",
    "    \n",
    "    # remove references and hashtags from text\n",
    "    text = re.sub(\"^a-zA-Z0-9$,.\", \"\", text)\n",
    "    \n",
    "    # remove multiple spaces from text\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # remove special characters from text\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n",
    "    \n",
    "    # stemming using porter stemmer from nltk package - msh a7sn 7aga - momken: lancaster, snowball\n",
    "   # text=' '.join([porter_stemmer.stem(word) for word in word_tokenize(text)])\n",
    "    # text=' '.join([lancaster_stemmer.stem(word) for word in word_tokenize(text)])\n",
    "    # text=' '.join([snowball_stemer.stem(word) for word in word_tokenize(text)])\n",
    "    \n",
    "    # lemmatizer using WordNetLemmatizer from nltk package\n",
    "    text=' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba67e633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:32.692887Z",
     "iopub.status.busy": "2022-09-30T03:58:32.692229Z",
     "iopub.status.idle": "2022-09-30T03:58:35.272525Z",
     "shell.execute_reply": "2022-09-30T03:58:35.271169Z"
    },
    "papermill": {
     "duration": 2.592953,
     "end_time": "2022-09-30T03:58:35.275522",
     "exception": false,
     "start_time": "2022-09-30T03:58:32.682569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/satyamchoubey/nltk_data...\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/satyamchoubey/nltk_data'\n    - '/opt/anaconda3/nltk_data'\n    - '/opt/anaconda3/share/nltk_data'\n    - '/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r3/xkrh3r1x2ql7n4nzh4vwp9_r0000gn/T/ipykernel_52794/1757671010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'omw-1.4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/r3/xkrh3r1x2ql7n4nzh4vwp9_r0000gn/T/ipykernel_52794/1757671010.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'omw-1.4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/r3/xkrh3r1x2ql7n4nzh4vwp9_r0000gn/T/ipykernel_52794/3866904919.py\u001b[0m in \u001b[0;36mtext_processing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\W'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# stemming using porter stemmer from nltk package - msh a7sn 7aga - momken: lancaster, snowball\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/satyamchoubey/nltk_data'\n    - '/opt/anaconda3/nltk_data'\n    - '/opt/anaconda3/share/nltk_data'\n    - '/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "data_copy = data2.copy()\n",
    "data_copy.Comment = data_copy.Comment.apply(lambda text: text_processing(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "470e1a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.295253Z",
     "iopub.status.busy": "2022-09-30T03:58:35.294756Z",
     "iopub.status.idle": "2022-09-30T03:58:35.301359Z",
     "shell.execute_reply": "2022-09-30T03:58:35.300315Z"
    },
    "papermill": {
     "duration": 0.019857,
     "end_time": "2022-09-30T03:58:35.303744",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.283887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e85e43ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.322568Z",
     "iopub.status.busy": "2022-09-30T03:58:35.322152Z",
     "iopub.status.idle": "2022-09-30T03:58:35.334657Z",
     "shell.execute_reply": "2022-09-30T03:58:35.333606Z"
    },
    "papermill": {
     "duration": 0.024592,
     "end_time": "2022-09-30T03:58:35.337112",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.312520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love how Dr. Fate's design looks and how cool ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can’t get over how good everything looks. Dr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really hoping that this can save DC's movie un...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U cant deny how good this looks.Now if they ca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From this trailer, I have a feeling that this ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment\n",
       "0  Love how Dr. Fate's design looks and how cool ...          2\n",
       "1  I can’t get over how good everything looks. Dr...          2\n",
       "2  Really hoping that this can save DC's movie un...          2\n",
       "3  U cant deny how good this looks.Now if they ca...          2\n",
       "4  From this trailer, I have a feeling that this ...          2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = {\n",
    "    'Sentence':data_copy.Comment,\n",
    "    'Sentiment':data_copy['Sentiment']\n",
    "}\n",
    "\n",
    "processed_data = pd.DataFrame(processed_data)\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aebf0a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.356089Z",
     "iopub.status.busy": "2022-09-30T03:58:35.355663Z",
     "iopub.status.idle": "2022-09-30T03:58:35.367585Z",
     "shell.execute_reply": "2022-09-30T03:58:35.366347Z"
    },
    "papermill": {
     "duration": 0.023739,
     "end_time": "2022-09-30T03:58:35.369847",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.346108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "2    205\n",
       "1     39\n",
       "0     36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data['Sentiment'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34027eb3",
   "metadata": {
    "papermill": {
     "duration": 0.007729,
     "end_time": "2022-09-30T03:58:35.385638",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.377909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Balancing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653b400e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.403714Z",
     "iopub.status.busy": "2022-09-30T03:58:35.403219Z",
     "iopub.status.idle": "2022-09-30T03:58:35.418286Z",
     "shell.execute_reply": "2022-09-30T03:58:35.416801Z"
    },
    "papermill": {
     "duration": 0.027101,
     "end_time": "2022-09-30T03:58:35.420669",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.393568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_neutral = processed_data[(processed_data['Sentiment']==1)] \n",
    "df_negative = processed_data[(processed_data['Sentiment']==0)]\n",
    "df_positive = processed_data[(processed_data['Sentiment']==2)]\n",
    "\n",
    "# upsample minority classes\n",
    "df_negative_upsampled = resample(df_negative, \n",
    "                                 replace=True,    \n",
    "                                 n_samples= 205, \n",
    "                                 random_state=42)  \n",
    "\n",
    "df_neutral_upsampled = resample(df_neutral, \n",
    "                                 replace=True,    \n",
    "                                 n_samples= 205, \n",
    "                                 random_state=42)  \n",
    "\n",
    "\n",
    "# Concatenate the upsampled dataframes with the neutral dataframe\n",
    "final_data = pd.concat([df_negative_upsampled,df_neutral_upsampled,df_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fd40890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.439757Z",
     "iopub.status.busy": "2022-09-30T03:58:35.438786Z",
     "iopub.status.idle": "2022-09-30T03:58:35.449212Z",
     "shell.execute_reply": "2022-09-30T03:58:35.448012Z"
    },
    "papermill": {
     "duration": 0.022799,
     "end_time": "2022-09-30T03:58:35.451721",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.428922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "0    205\n",
       "1    205\n",
       "2    205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "568a0391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.470025Z",
     "iopub.status.busy": "2022-09-30T03:58:35.469534Z",
     "iopub.status.idle": "2022-09-30T03:58:35.479611Z",
     "shell.execute_reply": "2022-09-30T03:58:35.478266Z"
    },
    "papermill": {
     "duration": 0.022407,
     "end_time": "2022-09-30T03:58:35.482226",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.459819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The trailer looks sick I'm definitely watching this movie\",\n",
       " 'He actually looks like the villain in this trailer!!!',\n",
       " 'This movie is going to push DC to the top of comic book movies (for now)\\nAfter the disaster that was the early DCEU, the new M-She-U mess and two awesome projekts behind them (The Suicide Squad and Peacemaker) yeah, this is going to rock (pun kinda intended)',\n",
       " \"Damn this for sure I'm gonna watch...DC seems to be going on the right track now.\",\n",
       " 'okay… this looks absolutely incredible. DC making me look foolish for ever even being skeptical about this film. definitely seeing this opening weekend']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for sentence in final_data['Sentence']:\n",
    "    corpus.append(sentence)\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9c4bba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.500695Z",
     "iopub.status.busy": "2022-09-30T03:58:35.500279Z",
     "iopub.status.idle": "2022-09-30T03:58:35.527566Z",
     "shell.execute_reply": "2022-09-30T03:58:35.526157Z"
    },
    "papermill": {
     "duration": 0.039859,
     "end_time": "2022-09-30T03:58:35.530491",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.490632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = final_data.iloc[:, -1].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0da4226e",
   "metadata": {
    "papermill": {
     "duration": 0.008472,
     "end_time": "2022-09-30T03:58:35.547565",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.539093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Machine learning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8eeb1a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.566537Z",
     "iopub.status.busy": "2022-09-30T03:58:35.566015Z",
     "iopub.status.idle": "2022-09-30T03:58:35.601363Z",
     "shell.execute_reply": "2022-09-30T03:58:35.600020Z"
    },
    "papermill": {
     "duration": 0.048206,
     "end_time": "2022-09-30T03:58:35.604213",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.556007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f938b4d",
   "metadata": {
    "papermill": {
     "duration": 0.007955,
     "end_time": "2022-09-30T03:58:35.620484",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.612529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "215dbf53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.639427Z",
     "iopub.status.busy": "2022-09-30T03:58:35.638697Z",
     "iopub.status.idle": "2022-09-30T03:58:35.655365Z",
     "shell.execute_reply": "2022-09-30T03:58:35.653954Z"
    },
    "papermill": {
     "duration": 0.028963,
     "end_time": "2022-09-30T03:58:35.657729",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.628766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58,  0,  0],\n",
       "       [ 0, 70,  0],\n",
       "       [ 9,  1, 47]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2a14c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T03:58:35.677374Z",
     "iopub.status.busy": "2022-09-30T03:58:35.676595Z",
     "iopub.status.idle": "2022-09-30T03:58:35.683913Z",
     "shell.execute_reply": "2022-09-30T03:58:35.682141Z"
    },
    "papermill": {
     "duration": 0.020548,
     "end_time": "2022-09-30T03:58:35.686792",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.666244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9459459459459459\n"
     ]
    }
   ],
   "source": [
    "nb_score = accuracy_score(y_test, y_pred)\n",
    "print('accuracy',nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a016dff",
   "metadata": {
    "papermill": {
     "duration": 0.008174,
     "end_time": "2022-09-30T03:58:35.703689",
     "exception": false,
     "start_time": "2022-09-30T03:58:35.695515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.558683,
   "end_time": "2022-09-30T03:58:37.155936",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-30T03:58:19.597253",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
